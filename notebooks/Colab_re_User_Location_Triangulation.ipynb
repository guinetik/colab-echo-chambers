{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas_schema\n",
        "!pip install python-louvain\n",
        "!pip install python-highcharts\n",
        "!pip install bokeh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PE02Vat4ijW",
        "outputId": "b229d701-14cc-4308-8aac-bbc016d34e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas_schema\n",
            "  Downloading pandas_schema-0.3.6-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pandas_schema) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.9/dist-packages (from pandas_schema) (1.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pandas_schema) (23.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.19->pandas_schema) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.19->pandas_schema) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19->pandas_schema) (1.16.0)\n",
            "Installing collected packages: pandas_schema\n",
            "Successfully installed pandas_schema-0.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.9/dist-packages (0.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from python-louvain) (1.22.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from python-louvain) (3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-highcharts\n",
            "  Downloading python-highcharts-0.4.2.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.9/dist-packages (from python-highcharts) (3.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from python-highcharts) (0.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2->python-highcharts) (2.1.2)\n",
            "Building wheels for collected packages: python-highcharts\n",
            "  Building wheel for python-highcharts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-highcharts: filename=python_highcharts-0.4.2-py3-none-any.whl size=60717 sha256=28b4c6d3f9cb83990c807dd1d5bba280e12db1dfe6399602eb6be943f6f2c1f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/29/b5/6447651b55dd30315e1befe33c548bccfa440eb364f6b74251\n",
            "Successfully built python-highcharts\n",
            "Installing collected packages: python-highcharts\n",
            "Successfully installed python-highcharts-0.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.9/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.9/dist-packages (from bokeh) (8.4.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.9/dist-packages (from bokeh) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.9/dist-packages (from bokeh) (4.5.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.9/dist-packages (from bokeh) (3.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.9/dist-packages (from bokeh) (6.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.9/dist-packages (from bokeh) (6.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from bokeh) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.9->bokeh) (2.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import pandas_schema\n",
        "from pandas_schema import Column\n",
        "from pandas_schema.validation import CustomElementValidation\n",
        "import numpy as np\n",
        "from decimal import *\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from bokeh.io import output_notebook, show, save\n",
        "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, FactorRange, HoverTool\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.plotting import from_networkx\n",
        "import networkx as nx\n",
        "from bokeh.palettes import Blues8, Reds8, Purples8, Oranges8, Viridis8, Spectral8, Plasma256, d3, Turbo256\n",
        "from bokeh.transform import linear_cmap\n",
        "from networkx.algorithms import community\n",
        "from bokeh.models import EdgesAndLinkedNodes, NodesAndLinkedEdges\n",
        "output_notebook()\n",
        "default_date_format ='%d/%m/%Y'\n",
        "#\n",
        "def DownloadDataFrame(df, filename):\n",
        "  df.to_csv(filename, encoding = 'utf-8-sig', index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
        "  files.download(filename)\n",
        "#\n",
        "def ResetDFIndex(df):\n",
        "  df.index = pd.RangeIndex(len(df.index))\n",
        "  df.index = range(len(df.index))\n",
        "  return df\n",
        "#\n",
        "def CreateSubDataSet(df, columns, unique, sort):\n",
        "  df = CreateDatasetFromColabUsers(df)[columns].copy()\n",
        "  if(sort):\n",
        "    df = df.sort_values(sort, ascending=True)\n",
        "    if(unique):\n",
        "      idx = df[sort].drop_duplicates().index\n",
        "      event_types = df.loc[idx,:]\n",
        "  return ResetDFIndex(event_types)\n",
        "#\n",
        "def ExtractEventTypes(df, download):\n",
        "  event_type_ids = CreateSubDataSet(df, ['event_type_id', 'event_type_name'], True, 'event_type_id')\n",
        "  print(event_type_ids.shape)\n",
        "  event_type_names = CreateSubDataSet(df, ['event_type_id', 'event_type_name'], True, 'event_type_name')\n",
        "  print(event_type_names.shape)\n",
        "  if(len(event_type_ids) != len(event_type_names)):\n",
        "    print(\"event_type_id and event_type_name counts are different.\", len(event_type_ids), \"ids\", len(event_type_names), \"names\")\n",
        "  if(download):\n",
        "    DownloadDataFrame(event_type_ids, \"event_type_ids.csv\")\n",
        "    DownloadDataFrame(event_type_names, \"event_type_names.csv\")\n",
        "  return event_type_ids if len(event_type_ids) < len(event_type_names) else event_type_names\n",
        "#\n",
        "def check_decimal(dec):\n",
        "    try:\n",
        "        Decimal(dec)\n",
        "    except InvalidOperation:\n",
        "        return False\n",
        "    return True\n",
        "#\n",
        "def check_int(num):\n",
        "    try:\n",
        "        int(num)\n",
        "    except ValueError:\n",
        "        return False\n",
        "    return True\n",
        "#\n",
        "def check_string(test_string):\n",
        "    return check_null(test_string) and len(str(test_string)) > 0\n",
        "#\n",
        "def check_date(date):\n",
        "  try:\n",
        "      datetime.datetime.strptime(date, default_date_format)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "  #return check_string(date) and re.match(r'(\\d{4})-(\\d{2})-(\\d{2}) (\\d{1,2}):(\\d{2})', date) is not None\n",
        "#\n",
        "print(\"check_date should be false: \", check_date(\"\"))\n",
        "print(\"check_date should be false: \", check_date(\"2022-05-18\"))\n",
        "print(\"check_date should be true: \", check_date(\"03/03/2013\"))\n",
        "def check_null(d):\n",
        "    return not(d is None)\n",
        "#\n",
        "# define validation elements\n",
        "decimal_validation = [CustomElementValidation(lambda d: check_decimal(d), 'invalid decimal')]\n",
        "int_validation = [CustomElementValidation(lambda i: check_int(i), 'invalid integer')]\n",
        "null_validation = [CustomElementValidation(lambda d: check_null(d), 'field cannot be null')]\n",
        "string_validation = [CustomElementValidation(lambda s: check_string(s), 'invalid string')]\n",
        "date_validation = [CustomElementValidation(lambda s: check_date(s), 'invalid date')]\n",
        "#\n",
        "#\n",
        "def validate_colab_events(file, parse_dates):\n",
        "    print(\"validating colab_events file\")\n",
        "    # read the data\n",
        "    data = ReadCSV(file, parse_dates)\n",
        "    # define validation schema\n",
        "    schema = pandas_schema.Schema([\n",
        "            Column('event_id', null_validation+int_validation),\n",
        "            Column('user_id', null_validation+int_validation),\n",
        "            Column('description', string_validation),\n",
        "            Column('status', null_validation + string_validation),\n",
        "            Column('created_at', date_validation),\n",
        "            Column('event_type_id', null_validation + int_validation),\n",
        "            Column('event_type_name', null_validation + string_validation)\n",
        "            ])\n",
        "    # apply validation\n",
        "    errors = schema.validate(data)\n",
        "    errors_index_rows = [e.row for e in errors]\n",
        "    data_clean = data.drop(index=errors_index_rows)\n",
        "    if(len(errors) > 0):\n",
        "      # save data\n",
        "      #data_clean.update('\"' + data_clean[['description', 'status', 'created_at', 'event_type_name']].astype(str) + '\"')\n",
        "      #data_clean['event_type_id'] = data_clean['event_type_id'].astype('int')\n",
        "      print(data.shape)\n",
        "      print(data_clean.shape)\n",
        "      #DownloadDataFrame(data_clean, \"colab_events_cleaned.csv\")\n",
        "      DownloadDataFrame(pd.DataFrame({'errors':errors}), \"data_errors.txt\")\n",
        "      print(\"Errors found on CSV schema. Check out the data_errors.txt\")\n",
        "      return False\n",
        "    else:\n",
        "      print(\"File is clean\")\n",
        "      return True\n",
        "#\n",
        "def tipify_colab_events(df):\n",
        "  df.fillna(-1, inplace=True)\n",
        "  df['event_id'] = df['event_id'].astype('int')\n",
        "  df['user_id'] = df['user_id'].astype('int')\n",
        "  df['event_type_id'] = df['event_type_id'].astype('int')\n",
        "  return df\n",
        "#\n",
        "def validate_colab_users(file, parse_dates):\n",
        "    # read the data\n",
        "    print(\"validating colab_users file\")\n",
        "    data = ReadCSV(file, parse_dates).head(1)\n",
        "    # define validation schema\n",
        "    schema = pandas_schema.Schema([\n",
        "            Column('colab_user_id', null_validation+int_validation),\n",
        "            Column('gender', null_validation),\n",
        "            Column('birth_date', null_validation),\n",
        "            Column('city_id', null_validation),\n",
        "            Column('city_name', string_validation),\n",
        "            Column('state_id', null_validation),\n",
        "            Column('state_name', null_validation + string_validation),\n",
        "            Column('created_at', date_validation),\n",
        "            Column('last_sign_in_at', date_validation),\n",
        "            Column('device', {})\n",
        "            ])\n",
        "    print(data.columns)\n",
        "    # apply validation\n",
        "    errors = schema.validate(data)\n",
        "    errors_index_rows = [e.row for e in errors]\n",
        "    data_clean = data.drop(index=errors_index_rows)\n",
        "    if(len(errors) > 0):\n",
        "      # save data\n",
        "      print(data.shape)\n",
        "      print(data_clean.shape)\n",
        "      #DownloadDataFrame(data_clean, \"colab_users_cleaned.csv\")\n",
        "      DownloadDataFrame(pd.DataFrame({'errors':errors}), \"user_errors.txt\")\n",
        "      print(\"Errors found on CSV schema. Check out the user_errors.txt\")\n",
        "      return False\n",
        "    else:\n",
        "      print(\"File is clean\")\n",
        "      return True\n",
        "#\n",
        "def tipify_colab_users(df):\n",
        "  df.fillna(\"\", inplace=True)\n",
        "  df['colab_user_id'] = df['colab_user_id'].astype('int')\n",
        "  df['city_id'] = df['city_id'].astype('int')\n",
        "  df['state_id'] = df['state_id'].astype('int')\n",
        "  return df\n",
        "#\n",
        "def tipify_colab_followers(df):\n",
        "  df.fillna(-1, inplace=True)\n",
        "  df['source'] = df['source'].astype('int')\n",
        "  df['target'] = df['target'].astype('int')\n",
        "  return df\n",
        "#\n",
        "def CreateDatasetFromColabEvents(df):\n",
        "  dataset = df.copy()\n",
        "  return dataset\n",
        "#\n",
        "#\n",
        "def CreateDatasetFromColabUsers(df):\n",
        "  dataset = df.copy()\n",
        "  return dataset\n",
        "#\n",
        "def ReadCSV(filename, parse_dates):\n",
        "  df = pd.read_csv(filename,\n",
        "                           parse_dates=parse_dates,\n",
        "                           low_memory=False,\n",
        "                           quoting=csv.QUOTE_NONNUMERIC,\n",
        "                           quotechar='\"')\n",
        "  if(parse_dates):\n",
        "    for field in parse_dates:\n",
        "      try:\n",
        "        df[field] = pd.to_datetime(df[field])\n",
        "        df[field] = df[field].dt.strftime(default_date_format)\n",
        "      except ValueError:\n",
        "        print(\"error parsing date\", df[field])\n",
        "  #df[parse_dates].fillna(0, inplace=True)\n",
        "  #df[parse_dates] = pd.to_datetime(df[parse_dates])\n",
        "  #df[parse_dates] = df[parse_dates].dt.strftime('%d/%m/%Y')\n",
        "  return df\n",
        "#\n",
        "def ReadAndValidateColabUsers(file):\n",
        "  parse_dates = ['created_at', 'last_sign_in_at']\n",
        "  if (validate_colab_users(file, parse_dates)):\n",
        "    colab_users = tipify_colab_users(ReadCSV(file, parse_dates))\n",
        "    return colab_users\n",
        "#\n",
        "def ReadAndValidateColabEvents(file):\n",
        "  parse_dates = ['created_at']\n",
        "  if (validate_colab_events(file, parse_dates)):\n",
        "    colab_events = tipify_colab_events(ReadCSV(file, parse_dates))\n",
        "    return colab_events\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv_stUdv4cpM",
        "outputId": "ba2553c1-be6c-4232-b78b-634d6e9145c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check_date should be false:  False\n",
            "check_date should be false:  False\n",
            "check_date should be true:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDG1bTMlLUmb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "colab_events_url_geo = \"https://drive.google.com/uc?id=1u-IhA8TtOh5ilRXurEV7TXYN_VIjrWRg&export=download\" #All data - with GEO\n",
        "colab_events_geo = ReadCSV(colab_events_url_geo, None)\n",
        "\n",
        "# Read in the csv files\n",
        "users_df = pd.read_csv('colab_users_and_followers.csv')\n",
        "events_df = colab_events_geo\n",
        "\n",
        "# Create a dictionary to hold each user's possible home location\n",
        "home_locations = {}\n",
        "\n",
        "# Iterate through each user in the users dataframe\n",
        "for i, user in users_df.iterrows():\n",
        "    # Get all events associated with the user\n",
        "    user_events = events_df[events_df['user_id'] == user['colab_user_id']]\n",
        "\n",
        "    # If the user has no events associated with them, skip to the next user\n",
        "    if user_events.empty:\n",
        "        continue\n",
        "\n",
        "    # Calculate the average lat-lng of all events associated with the user\n",
        "    total_lat = user_events['lat'].sum()\n",
        "    total_lng = user_events['lng'].sum()\n",
        "    avg_lat = total_lat / len(user_events)\n",
        "    avg_lng = total_lng / len(user_events)\n",
        "\n",
        "    # Store the user's possible home location in the dictionary\n",
        "    home_locations[user['colab_user_id']] = (avg_lat, avg_lng)\n",
        "\n",
        "# Iterate through each user in the users dataframe again, this time adding their home location to the dataframe\n",
        "for i, user in users_df.iterrows():\n",
        "    # If the user has a possible home location stored in the dictionary, add it to the dataframe\n",
        "    if user['colab_user_id'] in home_locations:\n",
        "        users_df.at[i, 'lat'] = home_locations[user['colab_user_id']][0]\n",
        "        users_df.at[i, 'lng'] = home_locations[user['colab_user_id']][1]\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "users_df.to_csv('colab_users_with_home_location.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# usuários que tem postagens no colab\n",
        "#\n",
        "#colab_users_url = \"https://drive.google.com/uc?id=1-P0Y9q27tDWQq2HD5PYgySmu1UBlJwO7&export=download\" #2020-2022 Niteroi - Clean\n",
        "#colab_users_url = \"https://drive.google.com/uc?id=16gqijd_rNssCV2bWy09cyPJWh4c0ycbe&export=download\" #New File (all data)\n",
        "colab_users_url = \"https://drive.google.com/uc?id=1MCyRDc_lty7m2UVKeAFse2vDust2Mtg4&export=download\" #05-20 File (all data)\n",
        "colab_users = ReadAndValidateColabUsers(colab_users_url)\n",
        "print(colab_users.shape)\n",
        "colab_users.head(1)\n",
        "#\n",
        "# seguidores de usuarios que tem postagens no colab\n",
        "#\n",
        "colab_users_followers_url = \"https://drive.google.com/uc?id=125MHZFOmhok7avkMpxZiHEejZt9kLkXQ&export=download\" #New File (all data)\n",
        "#colab_users_followers_url = \"https://drive.google.com/uc?id=1lbIpMG_AoQrx_dlkDTqTHl9F7EvLlxyC&export=download\" #05-20 File (all data)\n",
        "colab_users_followers = ReadCSV(colab_users_followers_url, False)\n",
        "print(colab_users_followers.shape)\n",
        "colab_users_followers.head(1)\n",
        "##\n",
        "df1=colab_users\n",
        "df2=colab_users_followers\n",
        "##\n",
        "df_all = pd.concat([colab_users.set_index('colab_user_id'), colab_users_followers.set_index('colab_user_id')], axis='columns', keys=['First', 'Second'])\n",
        "df_final = df_all.swaplevel(axis='columns')[colab_users.columns[1:]]\n",
        "df_final\n",
        "#\n",
        "# concatenando usuários com seus seguidores em uma unica planilha sem duplicados\n",
        "#\n",
        "result = pd.concat([df1,df2])\n",
        "idx = np.unique(result[\"colab_user_id\"], return_index=True)[1]\n",
        "colab_users_and_followers =result.iloc[idx]\n",
        "colab_users_and_followers\n",
        "DownloadDataFrame(colab_users_and_followers, \"colab_users_and_followers.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "hU4gAWRH5eOB",
        "outputId": "240d7a5b-d25c-4396-adcc-ab6eb9c5dba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validating colab_users file\n",
            "Index(['colab_user_id', 'gender', 'birth_date', 'city_id', 'city_name',\n",
            "       'state_id', 'state_name', 'created_at', 'last_sign_in_at', 'device'],\n",
            "      dtype='object')\n",
            "File is clean\n",
            "(49353, 10)\n",
            "(19665, 10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c528f18f-d385-4c66-8ecb-fddcd9d0e65f\", \"colab_users_and_followers.csv\", 5744320)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}